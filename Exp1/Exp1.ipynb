{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a530160",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Calculate performance metrics for Logistic Regression\n",
    "    print(\"=\"*80)\n",
    "    print(\"LOGISTIC REGRESSION - PERFORMANCE METRICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Training set metrics\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred, zero_division=0)\n",
    "    train_recall = recall_score(y_train, y_train_pred, zero_division=0)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, zero_division=0)\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred_proba[:, 1])\n",
    "    \n",
    "    # Testing set metrics\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_recall = recall_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_f1 = f1_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_auc = roc_auc_score(y_test, y_test_pred_proba[:, 1])\n",
    "    \n",
    "    # Confusion matrix\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    \n",
    "    print(\"\\n--- Training Set Performance ---\")\n",
    "    print(f\"Accuracy:  {train_accuracy:.4f}\")\n",
    "    print(f\"Precision: {train_precision:.4f}\")\n",
    "    print(f\"Recall:    {train_recall:.4f}\")\n",
    "    print(f\"F1-Score:  {train_f1:.4f}\")\n",
    "    print(f\"AUC-ROC:   {train_auc:.4f}\")\n",
    "    \n",
    "    print(\"\\n--- Testing Set Performance ---\")\n",
    "    print(f\"Accuracy:  {test_accuracy:.4f}\")\n",
    "    print(f\"Precision: {test_precision:.4f}\")\n",
    "    print(f\"Recall:    {test_recall:.4f}\")\n",
    "    print(f\"F1-Score:  {test_f1:.4f}\")\n",
    "    print(f\"AUC-ROC:   {test_auc:.4f}\")\n",
    "    \n",
    "    print(\"\\n--- Confusion Matrix (Test Set) ---\")\n",
    "    print(cm)\n",
    "    print(f\"\\nTrue Negatives:  {cm[0,0]}\")\n",
    "    print(f\"False Positives: {cm[0,1]}\")\n",
    "    print(f\"False Negatives: {cm[1,0]}\")\n",
    "    print(f\"True Positives:  {cm[1,1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a54f0426",
   "metadata": {},
   "source": [
    "## 11. Final Conclusions and Recommendations\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Model Performance:**\n",
    "   - Logistic Regression is the appropriate model for this binary classification task\n",
    "   - The model achieves reasonable performance in predicting term deposit subscriptions\n",
    "   - After hyperparameter tuning, the model performance was optimized\n",
    "\n",
    "2. **Important Features:**\n",
    "   - Certain features (duration, previous outcomes, campaign type) have high influence on subscription prediction\n",
    "   - The model learned meaningful patterns from the data\n",
    "\n",
    "3. **Hyperparameter Tuning Impact:**\n",
    "   - GridSearchCV helped identify optimal regularization parameters\n",
    "   - Cross-validation ensured robust parameter selection\n",
    "\n",
    "4. **Recommendations:**\n",
    "   - For production deployment, use the tuned Logistic Regression model\n",
    "   - Consider adjusting the classification threshold based on business requirements\n",
    "   - Monitor model performance on new data regularly\n",
    "   - Collect additional features if classification accuracy needs improvement\n",
    "\n",
    "5. **Next Steps:**\n",
    "   - Explore ensemble methods (Random Forest, Gradient Boosting)\n",
    "   - Implement class imbalance handling techniques if needed\n",
    "   - Perform feature engineering to create more predictive features\n",
    "   - Test deep learning models for potential performance gains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5ca7304f",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'df' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mdf\u001b[49m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m      2\u001b[39m     \u001b[38;5;66;03m# Visualize tuning impact\u001b[39;00m\n\u001b[32m      3\u001b[39m     fig, axes = plt.subplots(\u001b[32m1\u001b[39m, \u001b[32m2\u001b[39m, figsize=(\u001b[32m15\u001b[39m, \u001b[32m5\u001b[39m))\n\u001b[32m      5\u001b[39m     \u001b[38;5;66;03m# Comparison bar chart\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'df' is not defined"
     ]
    }
   ],
   "source": [
    "if df is not None:\n",
    "    # Visualize tuning impact\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Comparison bar chart\n",
    "    x_pos = np.arange(len(comparison_df))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[0].bar(x_pos - width/2, comparison_df['Before Tuning'], width, label='Before Tuning', alpha=0.8, color='skyblue')\n",
    "    axes[0].bar(x_pos + width/2, comparison_df['After Tuning'], width, label='After Tuning', alpha=0.8, color='orange')\n",
    "    axes[0].set_xlabel('Metrics', fontweight='bold')\n",
    "    axes[0].set_ylabel('Score', fontweight='bold')\n",
    "    axes[0].set_title('Logistic Regression: Impact of Hyperparameter Tuning', fontweight='bold', fontsize=12)\n",
    "    axes[0].set_xticks(x_pos)\n",
    "    axes[0].set_xticklabels(comparison_df['Metric'], rotation=45)\n",
    "    axes[0].legend()\n",
    "    axes[0].set_ylim([0, 1.1])\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Improvement chart\n",
    "    colors = ['green' if x > 0 else 'red' for x in comparison_df['Improvement']]\n",
    "    axes[1].barh(comparison_df['Metric'], comparison_df['Improvement'], color=colors, alpha=0.7)\n",
    "    axes[1].set_xlabel('Improvement', fontweight='bold')\n",
    "    axes[1].set_title('Performance Improvement After Tuning', fontweight='bold', fontsize=12)\n",
    "    axes[1].axvline(x=0, color='black', linestyle='-', linewidth=0.8)\n",
    "    axes[1].grid(True, alpha=0.3, axis='x')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b701934",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Comparison: Before and After Tuning\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPARISON: BEFORE AND AFTER HYPERPARAMETER TUNING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    comparison_df = pd.DataFrame({\n",
    "        'Metric': ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC'],\n",
    "        'Before Tuning': [test_accuracy, test_precision, test_recall, test_f1, test_auc],\n",
    "        'After Tuning': [test_acc_tuned, test_prec_tuned, test_rec_tuned, test_f1_tuned, test_auc_tuned]\n",
    "    })\n",
    "    \n",
    "    comparison_df['Improvement'] = comparison_df['After Tuning'] - comparison_df['Before Tuning']\n",
    "    print(\"\\n\", comparison_df.to_string(index=False))\n",
    "    \n",
    "    # Top GridSearch results\n",
    "    print(\"\\n--- Top 10 GridSearch Results (by F1-Score) ---\")\n",
    "    results_df = pd.DataFrame(grid_search_lr.cv_results_)\n",
    "    results_df_sorted = results_df.sort_values('rank_test_score').head(10)\n",
    "    print(results_df_sorted[['param_C', 'param_penalty', 'param_solver', 'mean_test_score', 'std_test_score']].to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa6f21b2",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"Hyperparameter Tuning for Logistic Regression...\")\n",
    "    print(\"This may take a minute...\")\n",
    "    \n",
    "    # Define parameter grid\n",
    "    param_grid = {\n",
    "        'C': [0.001, 0.01, 0.1, 1, 10, 100, 1000],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear']\n",
    "    }\n",
    "    \n",
    "    # Create GridSearchCV object\n",
    "    grid_search_lr = GridSearchCV(\n",
    "        LogisticRegression(random_state=42, max_iter=1000),\n",
    "        param_grid,\n",
    "        cv=5,\n",
    "        scoring='f1',\n",
    "        n_jobs=-1,\n",
    "        verbose=1\n",
    "    )\n",
    "    \n",
    "    # Fit the grid search\n",
    "    grid_search_lr.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"LOGISTIC REGRESSION - HYPERPARAMETER TUNING RESULTS\")\n",
    "    print(\"=\"*80)\n",
    "    print(f\"\\nBest Parameters: {grid_search_lr.best_params_}\")\n",
    "    print(f\"Best Cross-Validation F1-Score: {grid_search_lr.best_score_:.4f}\")\n",
    "    \n",
    "    # Get best model\n",
    "    best_log_reg = grid_search_lr.best_estimator_\n",
    "    \n",
    "    # Predictions with best model\n",
    "    y_train_pred_best_lr = best_log_reg.predict(X_train_scaled)\n",
    "    y_test_pred_best_lr = best_log_reg.predict(X_test_scaled)\n",
    "    y_test_pred_proba_best_lr = best_log_reg.predict_proba(X_test_scaled)\n",
    "    \n",
    "    # Performance metrics with best model\n",
    "    print(\"\\n--- Best Model Performance on Training Set ---\")\n",
    "    print(f\"Accuracy:  {accuracy_score(y_train, y_train_pred_best_lr):.4f}\")\n",
    "    print(f\"Precision: {precision_score(y_train, y_train_pred_best_lr, zero_division=0):.4f}\")\n",
    "    print(f\"Recall:    {recall_score(y_train, y_train_pred_best_lr, zero_division=0):.4f}\")\n",
    "    print(f\"F1-Score:  {f1_score(y_train, y_train_pred_best_lr, zero_division=0):.4f}\")\n",
    "    \n",
    "    print(\"\\n--- Best Model Performance on Testing Set ---\")\n",
    "    test_acc_tuned = accuracy_score(y_test, y_test_pred_best_lr)\n",
    "    test_prec_tuned = precision_score(y_test, y_test_pred_best_lr, zero_division=0)\n",
    "    test_rec_tuned = recall_score(y_test, y_test_pred_best_lr, zero_division=0)\n",
    "    test_f1_tuned = f1_score(y_test, y_test_pred_best_lr, zero_division=0)\n",
    "    test_auc_tuned = roc_auc_score(y_test, y_test_pred_proba_best_lr[:, 1])\n",
    "    \n",
    "    print(f\"Accuracy:  {test_acc_tuned:.4f}\")\n",
    "    print(f\"Precision: {test_prec_tuned:.4f}\")\n",
    "    print(f\"Recall:    {test_rec_tuned:.4f}\")\n",
    "    print(f\"F1-Score:  {test_f1_tuned:.4f}\")\n",
    "    print(f\"AUC-ROC:   {test_auc_tuned:.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a25bdbb",
   "metadata": {},
   "source": [
    "## 10. Hyperparameter Tuning\n",
    "\n",
    "### 10.1 Logistic Regression Hyperparameter Tuning\n",
    "\n",
    "We will tune the regularization parameter `C` (inverse of regularization strength) using GridSearchCV with 5-fold cross-validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fd5b95f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Visualizations for Linear Regression\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Actual vs Predicted (Training)\n",
    "    axes[0, 0].scatter(y_train, y_train_pred_lr, alpha=0.5, s=10)\n",
    "    axes[0, 0].plot([y_train.min(), y_train.max()], [y_train.min(), y_train.max()], 'r--', lw=2)\n",
    "    axes[0, 0].set_xlabel('Actual Values', fontweight='bold')\n",
    "    axes[0, 0].set_ylabel('Predicted Values', fontweight='bold')\n",
    "    axes[0, 0].set_title('Actual vs Predicted - Training Set', fontweight='bold', fontsize=12)\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Actual vs Predicted (Testing)\n",
    "    axes[0, 1].scatter(y_test, y_test_pred_lr, alpha=0.5, s=10, color='green')\n",
    "    axes[0, 1].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "    axes[0, 1].set_xlabel('Actual Values', fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('Predicted Values', fontweight='bold')\n",
    "    axes[0, 1].set_title('Actual vs Predicted - Testing Set', fontweight='bold', fontsize=12)\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Residuals Plot\n",
    "    residuals = y_test - y_test_pred_lr\n",
    "    axes[1, 0].scatter(y_test_pred_lr, residuals, alpha=0.5, s=10, color='purple')\n",
    "    axes[1, 0].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "    axes[1, 0].set_xlabel('Predicted Values', fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Residuals', fontweight='bold')\n",
    "    axes[1, 0].set_title('Residual Plot - Testing Set', fontweight='bold', fontsize=12)\n",
    "    axes[1, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 4. Distribution of Residuals\n",
    "    axes[1, 1].hist(residuals, bins=30, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "    axes[1, 1].axvline(x=0, color='r', linestyle='--', lw=2)\n",
    "    axes[1, 1].set_xlabel('Residuals', fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Frequency', fontweight='bold')\n",
    "    axes[1, 1].set_title('Distribution of Residuals', fontweight='bold', fontsize=12)\n",
    "    axes[1, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c26aba3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Linear Regression Performance Metrics\n",
    "    print(\"=\"*80)\n",
    "    print(\"LINEAR REGRESSION PERFORMANCE METRICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Training set metrics\n",
    "    train_mse_lr = mean_squared_error(y_train, y_train_pred_lr)\n",
    "    train_rmse_lr = np.sqrt(train_mse_lr)\n",
    "    train_mae_lr = mean_absolute_error(y_train, y_train_pred_lr)\n",
    "    train_r2_lr = r2_score(y_train, y_train_pred_lr)\n",
    "    \n",
    "    # Testing set metrics\n",
    "    test_mse_lr = mean_squared_error(y_test, y_test_pred_lr)\n",
    "    test_rmse_lr = np.sqrt(test_mse_lr)\n",
    "    test_mae_lr = mean_absolute_error(y_test, y_test_pred_lr)\n",
    "    test_r2_lr = r2_score(y_test, y_test_pred_lr)\n",
    "    \n",
    "    print(\"\\n--- Training Set Performance ---\")\n",
    "    print(f\"Mean Squared Error (MSE):      {train_mse_lr:.6f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE):{train_rmse_lr:.6f}\")\n",
    "    print(f\"Mean Absolute Error (MAE):     {train_mae_lr:.6f}\")\n",
    "    print(f\"R² Score:                      {train_r2_lr:.6f}\")\n",
    "    \n",
    "    print(\"\\n--- Testing Set Performance ---\")\n",
    "    print(f\"Mean Squared Error (MSE):      {test_mse_lr:.6f}\")\n",
    "    print(f\"Root Mean Squared Error (RMSE):{test_rmse_lr:.6f}\")\n",
    "    print(f\"Mean Absolute Error (MAE):     {test_mae_lr:.6f}\")\n",
    "    print(f\"R² Score:                      {test_r2_lr:.6f}\")\n",
    "    \n",
    "    print(\"\\n--- Interpretation ---\")\n",
    "    print(\"Note: Linear Regression predicts continuous values between 0 and 1.\")\n",
    "    print(\"The model can be used for probability estimation by treating predictions as probabilities.\")\n",
    "    print(f\"Min predicted value: {y_test_pred_lr.min():.4f}\")\n",
    "    print(f\"Max predicted value: {y_test_pred_lr.max():.4f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b55761e3",
   "metadata": {},
   "source": [
    "### 9.2 Linear Regression Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3ec9d7dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Visualizations for Logistic Regression\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # 1. Confusion Matrix Heatmap\n",
    "    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', ax=axes[0, 0], cbar=False)\n",
    "    axes[0, 0].set_title('Confusion Matrix - Logistic Regression (Test Set)', fontweight='bold', fontsize=12)\n",
    "    axes[0, 0].set_ylabel('True Label')\n",
    "    axes[0, 0].set_xlabel('Predicted Label')\n",
    "    \n",
    "    # 2. ROC Curve\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_test_pred_proba[:, 1])\n",
    "    axes[0, 1].plot(fpr, tpr, color='blue', lw=2, label=f'ROC curve (AUC = {test_auc:.3f})')\n",
    "    axes[0, 1].plot([0, 1], [0, 1], color='red', lw=2, linestyle='--', label='Random Classifier')\n",
    "    axes[0, 1].set_xlabel('False Positive Rate', fontweight='bold')\n",
    "    axes[0, 1].set_ylabel('True Positive Rate', fontweight='bold')\n",
    "    axes[0, 1].set_title('ROC Curve - Logistic Regression (Test Set)', fontweight='bold', fontsize=12)\n",
    "    axes[0, 1].legend(loc='lower right')\n",
    "    axes[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. Performance Metrics Comparison\n",
    "    metrics = ['Accuracy', 'Precision', 'Recall', 'F1-Score', 'AUC-ROC']\n",
    "    train_metrics = [train_accuracy, train_precision, train_recall, train_f1, train_auc]\n",
    "    test_metrics = [test_accuracy, test_precision, test_recall, test_f1, test_auc]\n",
    "    \n",
    "    x = np.arange(len(metrics))\n",
    "    width = 0.35\n",
    "    \n",
    "    axes[1, 0].bar(x - width/2, train_metrics, width, label='Training', alpha=0.8)\n",
    "    axes[1, 0].bar(x + width/2, test_metrics, width, label='Testing', alpha=0.8)\n",
    "    axes[1, 0].set_xlabel('Metrics', fontweight='bold')\n",
    "    axes[1, 0].set_ylabel('Score', fontweight='bold')\n",
    "    axes[1, 0].set_title('Performance Metrics Comparison', fontweight='bold', fontsize=12)\n",
    "    axes[1, 0].set_xticks(x)\n",
    "    axes[1, 0].set_xticklabels(metrics, rotation=45)\n",
    "    axes[1, 0].legend()\n",
    "    axes[1, 0].set_ylim([0, 1.1])\n",
    "    axes[1, 0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # 4. Prediction Probability Distribution\n",
    "    axes[1, 1].hist(y_test_pred_proba[y_test == 0, 1], bins=30, alpha=0.6, label='Class 0 (No Subscription)', color='red')\n",
    "    axes[1, 1].hist(y_test_pred_proba[y_test == 1, 1], bins=30, alpha=0.6, label='Class 1 (Subscription)', color='green')\n",
    "    axes[1, 1].axvline(x=0.5, color='black', linestyle='--', linewidth=2, label='Decision Threshold')\n",
    "    axes[1, 1].set_xlabel('Predicted Probability', fontweight='bold')\n",
    "    axes[1, 1].set_ylabel('Frequency', fontweight='bold')\n",
    "    axes[1, 1].set_title('Prediction Probability Distribution', fontweight='bold', fontsize=12)\n",
    "    axes[1, 1].legend()\n",
    "    axes[1, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "304ae117",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Logistic Regression Performance Metrics\n",
    "    print(\"=\"*80)\n",
    "    print(\"LOGISTIC REGRESSION PERFORMANCE METRICS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Calculate metrics for training set\n",
    "    train_accuracy = accuracy_score(y_train, y_train_pred)\n",
    "    train_precision = precision_score(y_train, y_train_pred, zero_division=0)\n",
    "    train_recall = recall_score(y_train, y_train_pred, zero_division=0)\n",
    "    train_f1 = f1_score(y_train, y_train_pred, zero_division=0)\n",
    "    train_auc = roc_auc_score(y_train, y_train_pred_proba[:, 1])\n",
    "    \n",
    "    # Calculate metrics for testing set\n",
    "    test_accuracy = accuracy_score(y_test, y_test_pred)\n",
    "    test_precision = precision_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_recall = recall_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_f1 = f1_score(y_test, y_test_pred, zero_division=0)\n",
    "    test_auc = roc_auc_score(y_test, y_test_pred_proba[:, 1])\n",
    "    \n",
    "    print(\"\\n--- Training Set Performance ---\")\n",
    "    print(f\"Accuracy:  {train_accuracy:.4f}\")\n",
    "    print(f\"Precision: {train_precision:.4f}\")\n",
    "    print(f\"Recall:    {train_recall:.4f}\")\n",
    "    print(f\"F1-Score:  {train_f1:.4f}\")\n",
    "    print(f\"AUC-ROC:   {train_auc:.4f}\")\n",
    "    \n",
    "    print(\"\\n--- Testing Set Performance ---\")\n",
    "    print(f\"Accuracy:  {test_accuracy:.4f}\")\n",
    "    print(f\"Precision: {test_precision:.4f}\")\n",
    "    print(f\"Recall:    {test_recall:.4f}\")\n",
    "    print(f\"F1-Score:  {test_f1:.4f}\")\n",
    "    print(f\"AUC-ROC:   {test_auc:.4f}\")\n",
    "    \n",
    "    # Confusion Matrix\n",
    "    print(\"\\n--- Confusion Matrix (Test Set) ---\")\n",
    "    cm = confusion_matrix(y_test, y_test_pred)\n",
    "    print(cm)\n",
    "    print(f\"True Negatives:  {cm[0, 0]}\")\n",
    "    print(f\"False Positives: {cm[0, 1]}\")\n",
    "    print(f\"False Negatives: {cm[1, 0]}\")\n",
    "    print(f\"True Positives:  {cm[1, 1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "65c1aa9f",
   "metadata": {},
   "source": [
    "## 9. Performance Analysis\n",
    "\n",
    "### 9.1 Logistic Regression Performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "404b68da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Train Linear Regression model\n",
    "    lin_reg = LinearRegression()\n",
    "    lin_reg.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    print(\"Linear Regression Model Training Complete!\")\n",
    "    print(f\"\\nModel Parameters:\")\n",
    "    print(f\"Intercept: {lin_reg.intercept_:.6f}\")\n",
    "    print(f\"Number of features: {len(lin_reg.coef_)}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred_lr = lin_reg.predict(X_train_scaled)\n",
    "    y_test_pred_lr = lin_reg.predict(X_test_scaled)\n",
    "    \n",
    "    print(\"\\nPrediction Summary:\")\n",
    "    print(f\"Training predictions shape: {y_train_pred_lr.shape}\")\n",
    "    print(f\"Testing predictions shape: {y_test_pred_lr.shape}\")\n",
    "    print(f\"Training predictions (first 10): {y_train_pred_lr[:10]}\")\n",
    "    print(f\"Testing predictions (first 10): {y_test_pred_lr[:10]}\")\n",
    "    \n",
    "    # Feature coefficients\n",
    "    coef_df_lr = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Coefficient': lin_reg.coef_\n",
    "    }).sort_values('Coefficient', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Features by Coefficient:\")\n",
    "    print(coef_df_lr.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f9a0d84",
   "metadata": {},
   "source": [
    "## 8. Model Training - Linear Regression (Secondary Analysis)\n",
    "\n",
    "For comparison purposes, we also train a Linear Regression model. Note that Linear Regression predicts continuous values, but we can still use it for analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5d5f8430",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Visualize top features\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Top positive coefficients\n",
    "    top_positive = coef_df.head(10)\n",
    "    axes[0].barh(range(len(top_positive)), top_positive['Coefficient'].values, color='green', alpha=0.7)\n",
    "    axes[0].set_yticks(range(len(top_positive)))\n",
    "    axes[0].set_yticklabels(top_positive['Feature'].values)\n",
    "    axes[0].set_xlabel('Coefficient Value', fontweight='bold')\n",
    "    axes[0].set_title('Top 10 Positive Features', fontweight='bold')\n",
    "    axes[0].invert_yaxis()\n",
    "    \n",
    "    # Top negative coefficients\n",
    "    bottom_negative = coef_df.tail(10)\n",
    "    axes[1].barh(range(len(bottom_negative)), bottom_negative['Coefficient'].values, color='red', alpha=0.7)\n",
    "    axes[1].set_yticks(range(len(bottom_negative)))\n",
    "    axes[1].set_yticklabels(bottom_negative['Feature'].values)\n",
    "    axes[1].set_xlabel('Coefficient Value', fontweight='bold')\n",
    "    axes[1].set_title('Top 10 Negative Features', fontweight='bold')\n",
    "    axes[1].invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d639bc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Train Logistic Regression model\n",
    "    log_reg = LogisticRegression(random_state=42, max_iter=1000)\n",
    "    log_reg.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    print(\"Logistic Regression Model Training Complete!\")\n",
    "    print(f\"\\nModel Parameters:\")\n",
    "    print(f\"Intercept: {log_reg.intercept_[0]:.6f}\")\n",
    "    print(f\"Number of features: {len(log_reg.coef_[0])}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred = log_reg.predict(X_train_scaled)\n",
    "    y_test_pred = log_reg.predict(X_test_scaled)\n",
    "    \n",
    "    # Get probability predictions\n",
    "    y_train_pred_proba = log_reg.predict_proba(X_train_scaled)\n",
    "    y_test_pred_proba = log_reg.predict_proba(X_test_scaled)\n",
    "    \n",
    "    print(\"\\nPrediction Summary:\")\n",
    "    print(f\"Training predictions shape: {y_train_pred.shape}\")\n",
    "    print(f\"Testing predictions shape: {y_test_pred.shape}\")\n",
    "    print(f\"Training predictions (first 10): {y_train_pred[:10]}\")\n",
    "    print(f\"Testing predictions (first 10): {y_test_pred[:10]}\")\n",
    "    \n",
    "    # Feature coefficients\n",
    "    coef_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Coefficient': log_reg.coef_[0]\n",
    "    }).sort_values('Coefficient', ascending=False)\n",
    "    \n",
    "    print(\"\\nTop 10 Features by Coefficient (Importance):\")\n",
    "    print(coef_df.head(10))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6270fb1",
   "metadata": {},
   "source": [
    "## 7. Model Training - Logistic Regression (Primary Model)\n",
    "\n",
    "Logistic Regression is the primary model for this classification task as it predicts a binary outcome (subscription: yes/no)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f28ed0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Feature Scaling using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Convert back to dataframe for easier handling\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "    \n",
    "    print(\"Feature Scaling Completed!\")\n",
    "    print(\"\\nScaled Training Set - First 5 rows:\")\n",
    "    print(X_train_scaled.head())\n",
    "    print(\"\\nScaled Training Set - Statistics:\")\n",
    "    print(X_train_scaled.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a85cdd9",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Separate features and target\n",
    "    X = df_processed.drop('y', axis=1)\n",
    "    y = df_processed['y']\n",
    "    \n",
    "    # Split data into training and testing sets (70-30 split)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42, stratify=y)\n",
    "    \n",
    "    print(\"Data Split Summary:\")\n",
    "    print(f\"Training set size: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "    print(f\"Testing set size: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "    print(f\"Number of features: {X_train.shape[1]}\")\n",
    "    print(f\"\\nTraining set target distribution:\")\n",
    "    print(y_train.value_counts())\n",
    "    print(f\"\\nTesting set target distribution:\")\n",
    "    print(y_test.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e8466d55",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Encode categorical variables using Label Encoding\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    print(\"Categorical variables encoded successfully!\")\n",
    "    print(\"\\nDataset after encoding:\")\n",
    "    print(df_processed.head())\n",
    "    print(\"\\nData types after preprocessing:\")\n",
    "    print(df_processed.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "396ec707",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Create a copy of the dataframe for preprocessing\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Convert target variable to binary (1 for 'yes', 0 for 'no')\n",
    "    df_processed['y'] = (df_processed['y'] == 'yes').astype(int)\n",
    "    \n",
    "    # Identify categorical and numerical columns\n",
    "    categorical_cols = df_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = df_processed.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    \n",
    "    # Remove target variable from feature columns\n",
    "    if 'y' in numerical_cols:\n",
    "        numerical_cols.remove('y')\n",
    "    \n",
    "    print(\"Categorical Columns:\", categorical_cols)\n",
    "    print(\"Numerical Columns:\", numerical_cols)\n",
    "    print(\"\\nTotal Features:\", len(categorical_cols) + len(numerical_cols))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924adc8a",
   "metadata": {},
   "source": [
    "## 6. Data Preprocessing\n",
    "\n",
    "### 6.1 Data Cleaning and Preparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7cc8180",
   "metadata": {},
   "source": [
    "## 5. Methodology / Workflow\n",
    "\n",
    "### Experiment Workflow\n",
    "\n",
    "```\n",
    "┌─────────────────────────────┐\n",
    "│   1. Load Dataset           │\n",
    "│   (Bank Marketing Data)     │\n",
    "└──────────────┬──────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────┐\n",
    "│ 2. Exploratory Data         │\n",
    "│    Analysis (EDA)           │\n",
    "│  - Data profiling           │\n",
    "│  - Distribution analysis    │\n",
    "│  - Missing value check      │\n",
    "└──────────────┬──────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────┐\n",
    "│ 3. Data Preprocessing       │\n",
    "│  - Handle missing values    │\n",
    "│  - Encode categorical vars  │\n",
    "│  - Feature scaling          │\n",
    "│  - Remove/handle outliers   │\n",
    "└──────────────┬──────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────┐\n",
    "│ 4. Train-Test Split        │\n",
    "│  - 70% training            │\n",
    "│  - 30% testing             │\n",
    "└──────────────┬──────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────┐\n",
    "│ 5. Model Training           │\n",
    "│  - Linear Regression        │\n",
    "│  - Logistic Regression      │\n",
    "└──────────────┬──────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────┐\n",
    "│ 6. Model Evaluation         │\n",
    "│  - Performance metrics      │\n",
    "│  - Visualizations           │\n",
    "│  - Error analysis           │\n",
    "└──────────────┬──────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────┐\n",
    "│ 7. Hyperparameter Tuning    │\n",
    "│  - GridSearchCV             │\n",
    "│  - Cross-validation         │\n",
    "│  - Parameter optimization   │\n",
    "└──────────────┬──────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────┐\n",
    "│ 8. Final Performance        │\n",
    "│    Analysis & Comparison    │\n",
    "└─────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Step-by-Step Process:\n",
    "\n",
    "1. **Data Loading:** Import the dataset and examine its structure\n",
    "2. **EDA:** Analyze data characteristics, distributions, and relationships\n",
    "3. **Preprocessing:** Clean data, encode categorical variables, scale features\n",
    "4. **Train-Test Split:** Divide data into training (70%) and testing (30%) sets\n",
    "5. **Model Training:** Fit Linear and Logistic Regression models\n",
    "6. **Evaluation:** Assess model performance using appropriate metrics\n",
    "7. **Hyperparameter Tuning:** Optimize model parameters using GridSearchCV\n",
    "8. **Comparison:** Compare results and generate conclusions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed4ba8e7",
   "metadata": {},
   "source": [
    "## 4. Algorithm Limitations\n",
    "\n",
    "### 4.1 Linear Regression Limitations\n",
    "\n",
    "1. **Linearity Assumption:** Linear Regression assumes a linear relationship between features and target. If the relationship is non-linear, the model will perform poorly.\n",
    "\n",
    "2. **Sensitivity to Outliers:** Extreme values can significantly affect the model's coefficients and predictions, leading to biased estimates.\n",
    "\n",
    "3. **Feature Scaling Dependency:** The magnitude of coefficients is affected by the scale of features. Features must be scaled appropriately for fair comparison.\n",
    "\n",
    "4. **Multicollinearity Issues:** When features are highly correlated, it becomes difficult to determine individual feature effects and results in unstable estimates.\n",
    "\n",
    "5. **Independence Assumption:** Linear Regression assumes that observations are independent. Violated in time-series or hierarchical data.\n",
    "\n",
    "6. **Assumes Normally Distributed Errors:** The model assumes that residuals follow a normal distribution, which may not hold for all datasets.\n",
    "\n",
    "### 4.2 Logistic Regression Limitations\n",
    "\n",
    "1. **Binary Classification Limitation:** Standard Logistic Regression is designed for binary classification. Multiclass problems require specialized extensions (One-vs-Rest, Multinomial Logistic Regression).\n",
    "\n",
    "2. **Linear Decision Boundary:** Logistic Regression creates linear decision boundaries. Complex non-linear boundaries cannot be captured without feature engineering.\n",
    "\n",
    "3. **Requires Feature Scaling:** Like Linear Regression, Logistic Regression benefits from scaled features, especially when using regularization.\n",
    "\n",
    "4. **Imbalanced Dataset Issues:** With highly imbalanced datasets (e.g., 95% class 0, 5% class 1), the model tends to be biased toward the majority class.\n",
    "\n",
    "5. **Interpretability Challenges:** While coefficients represent feature importance, the interpretation is complex and can be misleading with correlated features.\n",
    "\n",
    "6. **Assumes Linearity in Log-Odds:** The model assumes a linear relationship between features and the log-odds of the target, which may not always be true."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "429ee088",
   "metadata": {},
   "source": [
    "## 3. Mathematical Formulation of Algorithms\n",
    "\n",
    "### 3.1 Linear Regression\n",
    "\n",
    "Linear Regression models the relationship between independent variables (features) and a continuous dependent variable (target) using a linear equation:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n$$\n",
    "\n",
    "Where:\n",
    "- $y$ is the predicted value\n",
    "- $\\beta_0$ is the intercept\n",
    "- $\\beta_i$ are the regression coefficients\n",
    "- $x_i$ are the input features\n",
    "- $n$ is the number of features\n",
    "\n",
    "**Cost Function (Ordinary Least Squares - OLS):**\n",
    "\n",
    "$$J(\\beta) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\beta(x^{(i)}) - y^{(i)})^2$$\n",
    "\n",
    "Where:\n",
    "- $m$ is the number of training samples\n",
    "- $h_\\beta(x^{(i)})$ is the predicted value\n",
    "- $y^{(i)}$ is the actual value\n",
    "\n",
    "### 3.2 Logistic Regression\n",
    "\n",
    "Logistic Regression is used for binary classification. It models the probability of a binary outcome using the sigmoid (logistic) function:\n",
    "\n",
    "$$p(y=1|x) = \\sigma(z) = \\frac{1}{1+e^{-z}}$$\n",
    "\n",
    "Where:\n",
    "$$z = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n$$\n",
    "\n",
    "**Cost Function (Log Loss / Cross-Entropy):**\n",
    "\n",
    "$$J(\\beta) = -\\frac{1}{m} \\sum_{i=1}^{m} [y^{(i)} \\log(h_\\beta(x^{(i)})) + (1-y^{(i)}) \\log(1-h_\\beta(x^{(i)}))]$$\n",
    "\n",
    "**Decision Rule:**\n",
    "- If $p(y=1|x) \\geq 0.5$, predict class 1\n",
    "- Otherwise, predict class 0\n",
    "\n",
    "The decision boundary is determined by the chosen probability threshold (typically 0.5)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc1622f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Target variable distribution\n",
    "    print(\"Target Variable Distribution:\")\n",
    "    print(df['y'].value_counts())\n",
    "    print(\"\\nTarget Variable Proportion:\")\n",
    "    print(df['y'].value_counts(normalize=True))\n",
    "    \n",
    "    # Visualize target distribution\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(14, 4))\n",
    "    \n",
    "    # Count plot\n",
    "    sns.countplot(x='y', data=df, ax=axes[0], palette='Set2')\n",
    "    axes[0].set_title('Distribution of Target Variable (Subscription)', fontsize=12, fontweight='bold')\n",
    "    axes[0].set_xlabel('Subscription (y)')\n",
    "    axes[0].set_ylabel('Count')\n",
    "    \n",
    "    # Pie chart\n",
    "    df['y'].value_counts().plot(kind='pie', ax=axes[1], autopct='%1.1f%%', startangle=90)\n",
    "    axes[1].set_title('Proportion of Subscriptions', fontsize=12, fontweight='bold')\n",
    "    axes[1].set_ylabel('')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c38bd6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"Dataset Shape:\", df.shape)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"First Few Rows:\")\n",
    "    print(df.head())\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Data Types:\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Missing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Statistical Summary:\")\n",
    "    print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc5172f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the bank marketing dataset\n",
    "# Note: Download from Kaggle and place in the same directory as this notebook\n",
    "# df = pd.read_csv('bank.csv', sep=';')\n",
    "\n",
    "# For demonstration purposes, we'll create a sample load structure\n",
    "# Replace the path with your actual dataset location\n",
    "try:\n",
    "    df = pd.read_csv('bank.csv', sep=';')\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset file 'bank.csv' not found.\")\n",
    "    print(\"Please download from: https://www.kaggle.com/datasets/janiobachmann/bank-marketing-dataset\")\n",
    "    print(\"and place it in the same directory as this notebook.\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a2b2ea4",
   "metadata": {},
   "source": [
    "## 2. Dataset Description\n",
    "\n",
    "The Bank Marketing dataset contains information about a marketing campaign of a Portuguese banking institution. The dataset aims to predict whether a client will subscribe to a term deposit based on their personal characteristics and interaction history with the bank.\n",
    "\n",
    "### Dataset Overview:\n",
    "- **Number of Records:** Approximately 45,211 samples\n",
    "- **Number of Features:** 17 input features + 1 target variable\n",
    "- **Target Variable:** `y` - whether the client subscribed to a term deposit (binary: 'yes' or 'no')\n",
    "- **Data Types:** Mix of numerical and categorical features\n",
    "\n",
    "### Features Description:\n",
    "1. **age** (numerical): Age of the client\n",
    "2. **job** (categorical): Type of job (admin., technician, services, management, retired, blue-collar, unemployed, entrepreneur, housemaid, unknown, self-employed, student)\n",
    "3. **marital** (categorical): Marital status (married, single, divorced, unknown)\n",
    "4. **education** (categorical): Education level (primary, secondary, tertiary, unknown)\n",
    "5. **default** (categorical): Has credit in default? (yes, no, unknown)\n",
    "6. **balance** (numerical): Annual balance in euros\n",
    "7. **housing** (categorical): Has housing loan? (yes, no, unknown)\n",
    "8. **loan** (categorical): Has personal loan? (yes, no, unknown)\n",
    "9. **contact** (categorical): Contact communication type (cellular, telephone, unknown)\n",
    "10. **day** (numerical): Last contact day of the month\n",
    "11. **month** (categorical): Last contact month of year\n",
    "12. **duration** (numerical): Last contact duration in seconds\n",
    "13. **campaign** (numerical): Number of contacts performed during this campaign for this client\n",
    "14. **pdays** (numerical): Number of days passed since previous campaign contact (-1 means client was not previously contacted)\n",
    "15. **previous** (numerical): Number of contacts performed before this campaign\n",
    "16. **poutcome** (categorical): Outcome of previous marketing campaign (unknown, other, failure, success)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89ee54be",
   "metadata": {},
   "source": [
    "## 1. Dataset Source\n",
    "\n",
    "**Dataset Name:** Bank Marketing Dataset  \n",
    "**Source:** https://www.kaggle.com/datasets/janiobachmann/bank-marketing-dataset  \n",
    "**Original Paper:** [Moro et al., 2014] S. Moro, P. Cortez and P. Rita. A Data-Driven Approach to Predict the Success of Bank Telemarketing. Decision Support Systems, Elsevier, 62:22-31, June 2014  \n",
    "**License:** CC0: Public Domain  \n",
    "**File Size:** 918.96 kB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b19925b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, LogisticRegression\n",
    "from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix, roc_auc_score, roc_curve\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c454117c",
   "metadata": {},
   "source": [
    "# Machine Learning Experiment 1: Linear and Logistic Regression on Bank Marketing Dataset\n",
    "\n",
    "**Experiment Title:** Predicting Term Deposit Subscriptions Using Linear and Logistic Regression  \n",
    "**Date:** February 2026  \n",
    "**Objective:** To implement and compare Linear and Logistic Regression models on the Bank Marketing dataset to predict customer subscription to term deposits."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
