{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "378321c7",
   "metadata": {},
   "source": [
    "## 12. Final Conclusions and Recommendations\n",
    "\n",
    "### Key Findings:\n",
    "\n",
    "1. **Model Performance Ranking (Test Set R²):**\n",
    "   - The three regression models show different performance characteristics\n",
    "   - Multiple Linear Regression provides baseline performance\n",
    "   - Lasso and Ridge regularization help control overfitting through different mechanisms\n",
    "\n",
    "2. **Feature Selection and Interpretation:**\n",
    "   - **Lasso:** Performs automatic feature selection by driving some coefficients to zero\n",
    "   - **Ridge:** Keeps all features but shrinks their coefficients proportionally\n",
    "   - **Multiple:** Uses all features without regularization\n",
    "\n",
    "3. **Regularization Impact:**\n",
    "   - Hyperparameter tuning significantly optimized both Lasso and Ridge models\n",
    "   - The optimal alpha values balance bias and variance\n",
    "   - Cross-validation with 5-fold helped prevent overfitting\n",
    "\n",
    "4. **Practical Implications:**\n",
    "   - For prediction accuracy: Select the model with highest test R² score\n",
    "   - For interpretability: Lasso provides cleaner feature sets\n",
    "   - For stability: Ridge handles multicollinearity better\n",
    "\n",
    "5. **Recommendations:**\n",
    "\n",
    "   **For this dataset:**\n",
    "   - Use the tuned model with the best test R² score for production\n",
    "   - Consider the model's interpretability requirements\n",
    "   - Ridge is generally preferred when all features are potentially important\n",
    "   - Lasso is preferred when feature selection is desired\n",
    "\n",
    "   **Best Practices:**\n",
    "   - Always perform hyperparameter tuning with cross-validation\n",
    "   - Compare models using multiple metrics (R², RMSE, MAE)\n",
    "   - Validate assumptions (linearity, homoscedasticity, normality)\n",
    "   - Monitor performance on test data to detect overfitting\n",
    "   - Consider ensemble methods (combining models) for further improvement\n",
    "\n",
    "6. **Next Steps:**\n",
    "   - Implement feature engineering to create interaction terms\n",
    "   - Explore non-linear models (Polynomial Regression, Tree-based methods)\n",
    "   - Experiment with Elastic Net (combination of L1 and L2)\n",
    "   - Validate results on completely held-out data\n",
    "   - Consider cross-validation with different stratification approaches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccaf9566",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Compare coefficients before and after tuning\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(18, 5))\n",
    "    \n",
    "    features = X_train.columns\n",
    "    \n",
    "    # Multiple Regression coefficients\n",
    "    coef_mult_abs = np.abs(mult_reg.coef_)\n",
    "    sorted_idx = np.argsort(coef_mult_abs)[-10:]\n",
    "    axes[0].barh(range(len(sorted_idx)), coef_mult_abs[sorted_idx], color='#1f77b4', alpha=0.7)\n",
    "    axes[0].set_yticks(range(len(sorted_idx)))\n",
    "    axes[0].set_yticklabels([features[i] for i in sorted_idx])\n",
    "    axes[0].set_xlabel('|Coefficient|', fontweight='bold')\n",
    "    axes[0].set_title('Multiple Regression - Top 10 Features', fontweight='bold', fontsize=11)\n",
    "    axes[0].invert_yaxis()\n",
    "    \n",
    "    # Lasso (tuned) coefficients\n",
    "    coef_lasso_abs = np.abs(best_lasso.coef_)\n",
    "    sorted_idx_lasso = np.argsort(coef_lasso_abs)[-10:]\n",
    "    axes[1].barh(range(len(sorted_idx_lasso)), coef_lasso_abs[sorted_idx_lasso], color='#ff7f0e', alpha=0.7)\n",
    "    axes[1].set_yticks(range(len(sorted_idx_lasso)))\n",
    "    axes[1].set_yticklabels([features[i] for i in sorted_idx_lasso])\n",
    "    axes[1].set_xlabel('|Coefficient|', fontweight='bold')\n",
    "    axes[1].set_title(f'Lasso (α={grid_search_lasso.best_params_[\"alpha\"]}) - Top 10 Features', fontweight='bold', fontsize=11)\n",
    "    axes[1].invert_yaxis()\n",
    "    \n",
    "    # Ridge (tuned) coefficients\n",
    "    coef_ridge_abs = np.abs(best_ridge.coef_)\n",
    "    sorted_idx_ridge = np.argsort(coef_ridge_abs)[-10:]\n",
    "    axes[2].barh(range(len(sorted_idx_ridge)), coef_ridge_abs[sorted_idx_ridge], color='#2ca02c', alpha=0.7)\n",
    "    axes[2].set_yticks(range(len(sorted_idx_ridge)))\n",
    "    axes[2].set_yticklabels([features[i] for i in sorted_idx_ridge])\n",
    "    axes[2].set_xlabel('|Coefficient|', fontweight='bold')\n",
    "    axes[2].set_title(f'Ridge (α={grid_search_ridge.best_params_[\"alpha\"]}) - Top 10 Features', fontweight='bold', fontsize=11)\n",
    "    axes[2].invert_yaxis()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aded0cd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Visualize tuning results\n",
    "    fig, axes = plt.subplots(1, 2, figsize=(15, 5))\n",
    "    \n",
    "    # Extract CV results for Lasso\n",
    "    lasso_cv_results = pd.DataFrame(grid_search_lasso.cv_results_)\n",
    "    lasso_alphas = lasso_cv_results['param_alpha'].values\n",
    "    lasso_mean_scores = lasso_cv_results['mean_test_score'].values\n",
    "    lasso_std_scores = lasso_cv_results['std_test_score'].values\n",
    "    \n",
    "    # Extract CV results for Ridge\n",
    "    ridge_cv_results = pd.DataFrame(grid_search_ridge.cv_results_)\n",
    "    ridge_alphas = ridge_cv_results['param_alpha'].values\n",
    "    ridge_mean_scores = ridge_cv_results['mean_test_score'].values\n",
    "    ridge_std_scores = ridge_cv_results['std_test_score'].values\n",
    "    \n",
    "    # Plot Lasso tuning\n",
    "    axes[0].errorbar(lasso_alphas, lasso_mean_scores, yerr=lasso_std_scores, \n",
    "                     fmt='o-', capsize=5, capthick=2, markersize=8, label='CV Score')\n",
    "    axes[0].axvline(x=grid_search_lasso.best_params_['alpha'], color='r', linestyle='--', linewidth=2, label='Best Alpha')\n",
    "    axes[0].set_xscale('log')\n",
    "    axes[0].set_xlabel('Alpha (log scale)', fontweight='bold')\n",
    "    axes[0].set_ylabel('Cross-Validation R² Score', fontweight='bold')\n",
    "    axes[0].set_title('Lasso Regression - Alpha Tuning', fontweight='bold', fontsize=12)\n",
    "    axes[0].legend()\n",
    "    axes[0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Plot Ridge tuning\n",
    "    axes[1].errorbar(ridge_alphas, ridge_mean_scores, yerr=ridge_std_scores, \n",
    "                     fmt='s-', capsize=5, capthick=2, markersize=8, color='orange', label='CV Score')\n",
    "    axes[1].axvline(x=grid_search_ridge.best_params_['alpha'], color='r', linestyle='--', linewidth=2, label='Best Alpha')\n",
    "    axes[1].set_xscale('log')\n",
    "    axes[1].set_xlabel('Alpha (log scale)', fontweight='bold')\n",
    "    axes[1].set_ylabel('Cross-Validation R² Score', fontweight='bold')\n",
    "    axes[1].set_title('Ridge Regression - Alpha Tuning', fontweight='bold', fontsize=12)\n",
    "    axes[1].legend()\n",
    "    axes[1].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17f2363b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Comparison: Before and After Tuning\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"BEFORE AND AFTER TUNING COMPARISON\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    comparison_tuning = pd.DataFrame({\n",
    "        'Model': ['Lasso (alpha=1.0)', 'Lasso (tuned)', 'Ridge (alpha=1.0)', 'Ridge (tuned)'],\n",
    "        'Train R²': [train_r2_lasso, best_lasso_r2_train, train_r2_ridge, best_ridge_r2_train],\n",
    "        'Test R²': [test_r2_lasso, best_lasso_r2_test, test_r2_ridge, best_ridge_r2_test],\n",
    "        'Test RMSE': [test_rmse_lasso, best_lasso_rmse_test, test_rmse_ridge, best_ridge_rmse_test],\n",
    "        'Test MAE': [test_mae_lasso, best_lasso_mae_test, test_mae_ridge, best_ridge_mae_test]\n",
    "    })\n",
    "    \n",
    "    print(\"\\n\", comparison_tuning.to_string(index=False))\n",
    "    \n",
    "    # Lasso improvement\n",
    "    lasso_r2_improvement = best_lasso_r2_test - test_r2_lasso\n",
    "    ridge_r2_improvement = best_ridge_r2_test - test_r2_ridge\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"IMPROVEMENT AFTER TUNING (Test Set R² Score)\")\n",
    "    print(\"=\"*100)\n",
    "    print(f\"\\nLasso R² Improvement:  {lasso_r2_improvement:+.6f}\")\n",
    "    print(f\"Ridge R² Improvement:  {ridge_r2_improvement:+.6f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3330f3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # GridSearchCV for Ridge\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"RIDGE REGRESSION - HYPERPARAMETER TUNING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    grid_search_ridge = GridSearchCV(\n",
    "        Ridge(random_state=42),\n",
    "        {'alpha': alpha_values},\n",
    "        cv=5,\n",
    "        scoring='r2',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    grid_search_ridge.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    print(f\"\\nBest Alpha for Ridge: {grid_search_ridge.best_params_['alpha']}\")\n",
    "    print(f\"Best Cross-Validation R² Score: {grid_search_ridge.best_score_:.6f}\")\n",
    "    \n",
    "    # Get best Ridge model\n",
    "    best_ridge = grid_search_ridge.best_estimator_\n",
    "    y_train_pred_best_ridge = best_ridge.predict(X_train_scaled)\n",
    "    y_test_pred_best_ridge = best_ridge.predict(X_test_scaled)\n",
    "    \n",
    "    best_ridge_r2_train = r2_score(y_train, y_train_pred_best_ridge)\n",
    "    best_ridge_r2_test = r2_score(y_test, y_test_pred_best_ridge)\n",
    "    best_ridge_rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred_best_ridge))\n",
    "    best_ridge_mae_test = mean_absolute_error(y_test, y_test_pred_best_ridge)\n",
    "    \n",
    "    print(f\"\\n--- Best Ridge Model Performance ---\")\n",
    "    print(f\"Training R²:   {best_ridge_r2_train:.6f}\")\n",
    "    print(f\"Testing R²:    {best_ridge_r2_test:.6f}\")\n",
    "    print(f\"Testing RMSE:  ${best_ridge_rmse_test:.2f}\")\n",
    "    print(f\"Testing MAE:   ${best_ridge_mae_test:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b39465d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"Hyperparameter Tuning for Lasso and Ridge Regression...\")\n",
    "    print(\"This may take a moment...\\n\")\n",
    "    \n",
    "    # Define alpha values to test\n",
    "    alpha_values = [0.001, 0.01, 0.1, 0.5, 1, 5, 10, 50, 100, 500, 1000]\n",
    "    \n",
    "    # GridSearchCV for Lasso\n",
    "    print(\"=\"*80)\n",
    "    print(\"LASSO REGRESSION - HYPERPARAMETER TUNING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    grid_search_lasso = GridSearchCV(\n",
    "        Lasso(random_state=42),\n",
    "        {'alpha': alpha_values},\n",
    "        cv=5,\n",
    "        scoring='r2',\n",
    "        n_jobs=-1,\n",
    "        verbose=0\n",
    "    )\n",
    "    \n",
    "    grid_search_lasso.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    print(f\"\\nBest Alpha for Lasso: {grid_search_lasso.best_params_['alpha']}\")\n",
    "    print(f\"Best Cross-Validation R² Score: {grid_search_lasso.best_score_:.6f}\")\n",
    "    \n",
    "    # Get best Lasso model\n",
    "    best_lasso = grid_search_lasso.best_estimator_\n",
    "    y_train_pred_best_lasso = best_lasso.predict(X_train_scaled)\n",
    "    y_test_pred_best_lasso = best_lasso.predict(X_test_scaled)\n",
    "    \n",
    "    best_lasso_r2_train = r2_score(y_train, y_train_pred_best_lasso)\n",
    "    best_lasso_r2_test = r2_score(y_test, y_test_pred_best_lasso)\n",
    "    best_lasso_rmse_test = np.sqrt(mean_squared_error(y_test, y_test_pred_best_lasso))\n",
    "    best_lasso_mae_test = mean_absolute_error(y_test, y_test_pred_best_lasso)\n",
    "    \n",
    "    print(f\"\\n--- Best Lasso Model Performance ---\")\n",
    "    print(f\"Training R²:   {best_lasso_r2_train:.6f}\")\n",
    "    print(f\"Testing R²:    {best_lasso_r2_test:.6f}\")\n",
    "    print(f\"Testing RMSE:  ${best_lasso_rmse_test:.2f}\")\n",
    "    print(f\"Testing MAE:   ${best_lasso_mae_test:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "982f2f13",
   "metadata": {},
   "source": [
    "## 11. Hyperparameter Tuning\n",
    "\n",
    "### 11.1 Alpha Parameter Tuning for Lasso and Ridge Regression\n",
    "\n",
    "We will use GridSearchCV to find optimal alpha values for both Lasso and Ridge models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e135d121",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Performance metrics comparison visualization\n",
    "    fig, axes = plt.subplots(1, 3, figsize=(16, 5))\n",
    "    \n",
    "    models = ['Multiple', 'Lasso', 'Ridge']\n",
    "    r2_scores = [test_r2_mult, test_r2_lasso, test_r2_ridge]\n",
    "    rmse_values = [test_rmse_mult, test_rmse_lasso, test_rmse_ridge]\n",
    "    mae_values = [test_mae_mult, test_mae_lasso, test_mae_ridge]\n",
    "    \n",
    "    # R² Score comparison\n",
    "    axes[0].bar(models, r2_scores, color=['#1f77b4', '#ff7f0e', '#2ca02c'], alpha=0.7, edgecolor='black')\n",
    "    axes[0].set_ylabel('R² Score', fontweight='bold')\n",
    "    axes[0].set_title('R² Score Comparison (Test Set)', fontweight='bold', fontsize=12)\n",
    "    axes[0].set_ylim([0, 1])\n",
    "    for i, v in enumerate(r2_scores):\n",
    "        axes[0].text(i, v + 0.02, f'{v:.4f}', ha='center', fontweight='bold')\n",
    "    axes[0].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # RMSE comparison\n",
    "    axes[1].bar(models, rmse_values, color=['#1f77b4', '#ff7f0e', '#2ca02c'], alpha=0.7, edgecolor='black')\n",
    "    axes[1].set_ylabel('RMSE ($)', fontweight='bold')\n",
    "    axes[1].set_title('RMSE Comparison (Test Set)', fontweight='bold', fontsize=12)\n",
    "    for i, v in enumerate(rmse_values):\n",
    "        axes[1].text(i, v + 500, f'${v:.0f}', ha='center', fontweight='bold')\n",
    "    axes[1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # MAE comparison\n",
    "    axes[2].bar(models, mae_values, color=['#1f77b4', '#ff7f0e', '#2ca02c'], alpha=0.7, edgecolor='black')\n",
    "    axes[2].set_ylabel('MAE ($)', fontweight='bold')\n",
    "    axes[2].set_title('MAE Comparison (Test Set)', fontweight='bold', fontsize=12)\n",
    "    for i, v in enumerate(mae_values):\n",
    "        axes[2].text(i, v + 300, f'${v:.0f}', ha='center', fontweight='bold')\n",
    "    axes[2].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1aefd67b",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Comprehensive visualization of performance\n",
    "    fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "    \n",
    "    models = ['Multiple', 'Lasso', 'Ridge']\n",
    "    colors = ['#1f77b4', '#ff7f0e', '#2ca02c']\n",
    "    \n",
    "    # Row 1: Actual vs Predicted for Test Set\n",
    "    for idx, (pred, model, color) in enumerate(zip([y_test_pred_mult, y_test_pred_lasso, y_test_pred_ridge], models, colors)):\n",
    "        axes[0, idx].scatter(y_test, pred, alpha=0.5, s=20, color=color)\n",
    "        axes[0, idx].plot([y_test.min(), y_test.max()], [y_test.min(), y_test.max()], 'r--', lw=2)\n",
    "        axes[0, idx].set_xlabel('Actual Values ($)', fontweight='bold')\n",
    "        axes[0, idx].set_ylabel('Predicted Values ($)', fontweight='bold')\n",
    "        axes[0, idx].set_title(f'{model} - Actual vs Predicted', fontweight='bold', fontsize=11)\n",
    "        axes[0, idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Row 2: Residuals for Test Set\n",
    "    for idx, (pred, model, color) in enumerate(zip([y_test_pred_mult, y_test_pred_lasso, y_test_pred_ridge], models, colors)):\n",
    "        residuals = y_test - pred\n",
    "        axes[1, idx].scatter(pred, residuals, alpha=0.5, s=20, color=color)\n",
    "        axes[1, idx].axhline(y=0, color='r', linestyle='--', lw=2)\n",
    "        axes[1, idx].set_xlabel('Predicted Values ($)', fontweight='bold')\n",
    "        axes[1, idx].set_ylabel('Residuals ($)', fontweight='bold')\n",
    "        axes[1, idx].set_title(f'{model} - Residual Plot', fontweight='bold', fontsize=11)\n",
    "        axes[1, idx].grid(True, alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4a33f8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Calculate performance metrics for all three models\n",
    "    print(\"=\"*100)\n",
    "    print(\"PERFORMANCE METRICS COMPARISON - ALL MODELS\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    # Multiple Regression\n",
    "    train_mse_mult = mean_squared_error(y_train, y_train_pred_mult)\n",
    "    train_rmse_mult = np.sqrt(train_mse_mult)\n",
    "    train_mae_mult = mean_absolute_error(y_train, y_train_pred_mult)\n",
    "    train_r2_mult = r2_score(y_train, y_train_pred_mult)\n",
    "    \n",
    "    test_mse_mult = mean_squared_error(y_test, y_test_pred_mult)\n",
    "    test_rmse_mult = np.sqrt(test_mse_mult)\n",
    "    test_mae_mult = mean_absolute_error(y_test, y_test_pred_mult)\n",
    "    test_r2_mult = r2_score(y_test, y_test_pred_mult)\n",
    "    \n",
    "    # Lasso Regression\n",
    "    train_mse_lasso = mean_squared_error(y_train, y_train_pred_lasso)\n",
    "    train_rmse_lasso = np.sqrt(train_mse_lasso)\n",
    "    train_mae_lasso = mean_absolute_error(y_train, y_train_pred_lasso)\n",
    "    train_r2_lasso = r2_score(y_train, y_train_pred_lasso)\n",
    "    \n",
    "    test_mse_lasso = mean_squared_error(y_test, y_test_pred_lasso)\n",
    "    test_rmse_lasso = np.sqrt(test_mse_lasso)\n",
    "    test_mae_lasso = mean_absolute_error(y_test, y_test_pred_lasso)\n",
    "    test_r2_lasso = r2_score(y_test, y_test_pred_lasso)\n",
    "    \n",
    "    # Ridge Regression\n",
    "    train_mse_ridge = mean_squared_error(y_train, y_train_pred_ridge)\n",
    "    train_rmse_ridge = np.sqrt(train_mse_ridge)\n",
    "    train_mae_ridge = mean_absolute_error(y_train, y_train_pred_ridge)\n",
    "    train_r2_ridge = r2_score(y_train, y_train_pred_ridge)\n",
    "    \n",
    "    test_mse_ridge = mean_squared_error(y_test, y_test_pred_ridge)\n",
    "    test_rmse_ridge = np.sqrt(test_mse_ridge)\n",
    "    test_mae_ridge = mean_absolute_error(y_test, y_test_pred_ridge)\n",
    "    test_r2_ridge = r2_score(y_test, y_test_pred_ridge)\n",
    "    \n",
    "    # Create comparison dataframe\n",
    "    metrics_comparison = pd.DataFrame({\n",
    "        'Model': ['Multiple Reg', 'Multiple Reg', 'Lasso', 'Lasso', 'Ridge', 'Ridge'],\n",
    "        'Dataset': ['Train', 'Test', 'Train', 'Test', 'Train', 'Test'],\n",
    "        'MSE': [train_mse_mult, test_mse_mult, train_mse_lasso, test_mse_lasso, train_mse_ridge, test_mse_ridge],\n",
    "        'RMSE': [train_rmse_mult, test_rmse_mult, train_rmse_lasso, test_rmse_lasso, train_rmse_ridge, test_rmse_ridge],\n",
    "        'MAE': [train_mae_mult, test_mae_mult, train_mae_lasso, test_mae_lasso, train_mae_ridge, test_mae_ridge],\n",
    "        'R² Score': [train_r2_mult, test_r2_mult, train_r2_lasso, test_r2_lasso, train_r2_ridge, test_r2_ridge]\n",
    "    })\n",
    "    \n",
    "    print(\"\\n\", metrics_comparison.to_string(index=False))\n",
    "    \n",
    "    # Summary statistics\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\"TEST SET PERFORMANCE SUMMARY\")\n",
    "    print(\"=\"*100)\n",
    "    summary_df = pd.DataFrame({\n",
    "        'Model': ['Multiple', 'Lasso', 'Ridge'],\n",
    "        'R² Score': [test_r2_mult, test_r2_lasso, test_r2_ridge],\n",
    "        'RMSE ($)': [test_rmse_mult, test_rmse_lasso, test_rmse_ridge],\n",
    "        'MAE ($)': [test_mae_mult, test_mae_lasso, test_mae_ridge],\n",
    "        'MSE': [test_mse_mult, test_mse_lasso, test_mse_ridge]\n",
    "    })\n",
    "    print(\"\\n\", summary_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8eb4011",
   "metadata": {},
   "source": [
    "## 10. Performance Analysis\n",
    "\n",
    "### 10.1 Comparing Model Performance Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5c5ce0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Train Ridge Regression model with default alpha\n",
    "    ridge_reg = Ridge(alpha=1.0, random_state=42)\n",
    "    ridge_reg.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    print(\"Ridge Regression Model Training Complete (alpha=1.0)!\")\n",
    "    print(f\"\\nModel Parameters:\")\n",
    "    print(f\"Intercept: ${ridge_reg.intercept_:.2f}\")\n",
    "    print(f\"Number of features: {len(ridge_reg.coef_)}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred_ridge = ridge_reg.predict(X_train_scaled)\n",
    "    y_test_pred_ridge = ridge_reg.predict(X_test_scaled)\n",
    "    \n",
    "    print(\"\\nPrediction Summary:\")\n",
    "    print(f\"Training predictions shape: {y_train_pred_ridge.shape}\")\n",
    "    print(f\"Testing predictions shape: {y_test_pred_ridge.shape}\")\n",
    "    \n",
    "    # Feature coefficients\n",
    "    coef_df_ridge = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Coefficient': ridge_reg.coef_\n",
    "    }).sort_values('Coefficient', ascending=False, key=abs)\n",
    "    \n",
    "    print(\"\\nRidge Feature Coefficients (sorted by absolute value):\")\n",
    "    print(coef_df_ridge.to_string(index=False))\n",
    "    \n",
    "    # All coefficients should be non-zero in Ridge\n",
    "    non_zero_ridge = (ridge_reg.coef_ != 0).sum()\n",
    "    print(f\"\\nNumber of non-zero coefficients: {non_zero_ridge}/{len(ridge_reg.coef_)} (Ridge keeps all features)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a8b686",
   "metadata": {},
   "source": [
    "## 9. Model Training - Ridge Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "546f6de3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Train Lasso Regression model with default alpha\n",
    "    lasso_reg = Lasso(alpha=1.0, random_state=42)\n",
    "    lasso_reg.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    print(\"Lasso Regression Model Training Complete (alpha=1.0)!\")\n",
    "    print(f\"\\nModel Parameters:\")\n",
    "    print(f\"Intercept: ${lasso_reg.intercept_:.2f}\")\n",
    "    print(f\"Number of features: {len(lasso_reg.coef_)}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred_lasso = lasso_reg.predict(X_train_scaled)\n",
    "    y_test_pred_lasso = lasso_reg.predict(X_test_scaled)\n",
    "    \n",
    "    print(\"\\nPrediction Summary:\")\n",
    "    print(f\"Training predictions shape: {y_train_pred_lasso.shape}\")\n",
    "    print(f\"Testing predictions shape: {y_test_pred_lasso.shape}\")\n",
    "    \n",
    "    # Feature coefficients\n",
    "    coef_df_lasso = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Coefficient': lasso_reg.coef_\n",
    "    }).sort_values('Coefficient', ascending=False, key=abs)\n",
    "    \n",
    "    print(\"\\nLasso Feature Coefficients (sorted by absolute value):\")\n",
    "    print(coef_df_lasso.to_string(index=False))\n",
    "    \n",
    "    # Count non-zero coefficients\n",
    "    non_zero = (lasso_reg.coef_ != 0).sum()\n",
    "    print(f\"\\nNumber of non-zero coefficients: {non_zero}/{len(lasso_reg.coef_)}\")\n",
    "    print(f\"Features selected by Lasso: {list(coef_df_lasso[coef_df_lasso['Coefficient'] != 0]['Feature'].values)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e2382ba",
   "metadata": {},
   "source": [
    "## 8. Model Training - Lasso Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8515b2e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Train Multiple Linear Regression model\n",
    "    mult_reg = LinearRegression()\n",
    "    mult_reg.fit(X_train_scaled, y_train)\n",
    "    \n",
    "    print(\"Multiple Linear Regression Model Training Complete!\")\n",
    "    print(f\"\\nModel Parameters:\")\n",
    "    print(f\"Intercept: ${mult_reg.intercept_:.2f}\")\n",
    "    print(f\"Number of features: {len(mult_reg.coef_)}\")\n",
    "    \n",
    "    # Make predictions\n",
    "    y_train_pred_mult = mult_reg.predict(X_train_scaled)\n",
    "    y_test_pred_mult = mult_reg.predict(X_test_scaled)\n",
    "    \n",
    "    print(\"\\nPrediction Summary:\")\n",
    "    print(f\"Training predictions shape: {y_train_pred_mult.shape}\")\n",
    "    print(f\"Testing predictions shape: {y_test_pred_mult.shape}\")\n",
    "    \n",
    "    # Feature coefficients\n",
    "    coef_df = pd.DataFrame({\n",
    "        'Feature': X_train.columns,\n",
    "        'Coefficient': mult_reg.coef_\n",
    "    }).sort_values('Coefficient', ascending=False, key=abs)\n",
    "    \n",
    "    print(\"\\nFeature Coefficients (sorted by absolute value):\")\n",
    "    print(coef_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99b149df",
   "metadata": {},
   "source": [
    "## 7. Model Training - Multiple Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8745ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Feature Scaling using StandardScaler\n",
    "    scaler = StandardScaler()\n",
    "    X_train_scaled = scaler.fit_transform(X_train)\n",
    "    X_test_scaled = scaler.transform(X_test)\n",
    "    \n",
    "    # Convert to dataframe\n",
    "    X_train_scaled = pd.DataFrame(X_train_scaled, columns=X_train.columns)\n",
    "    X_test_scaled = pd.DataFrame(X_test_scaled, columns=X_test.columns)\n",
    "    \n",
    "    print(\"Feature Scaling Completed!\")\n",
    "    print(\"\\nScaled Training Set Statistics:\")\n",
    "    print(X_train_scaled.describe())\n",
    "    print(\"\\nScaled Features (first 5 rows of training set):\")\n",
    "    print(X_train_scaled.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5e50ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Separate features and target\n",
    "    X = df_processed.drop('charges', axis=1)\n",
    "    y = df_processed['charges']\n",
    "    \n",
    "    # Train-test split (70-30)\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.30, random_state=42)\n",
    "    \n",
    "    print(\"Data Split Summary:\")\n",
    "    print(f\"Training set size: {X_train.shape[0]} samples ({X_train.shape[0]/len(X)*100:.1f}%)\")\n",
    "    print(f\"Testing set size: {X_test.shape[0]} samples ({X_test.shape[0]/len(X)*100:.1f}%)\")\n",
    "    print(f\"Number of features: {X_train.shape[1]}\")\n",
    "    \n",
    "    print(\"\\nFeature names:\", list(X.columns))\n",
    "    print(\"\\nTraining set target statistics:\")\n",
    "    print(f\"  Mean: ${y_train.mean():.2f}\")\n",
    "    print(f\"  Std: ${y_train.std():.2f}\")\n",
    "    print(f\"  Min: ${y_train.min():.2f}\")\n",
    "    print(f\"  Max: ${y_train.max():.2f}\")\n",
    "    \n",
    "    print(\"\\nTesting set target statistics:\")\n",
    "    print(f\"  Mean: ${y_test.mean():.2f}\")\n",
    "    print(f\"  Std: ${y_test.std():.2f}\")\n",
    "    print(f\"  Min: ${y_test.min():.2f}\")\n",
    "    print(f\"  Max: ${y_test.max():.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95fc5a68",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Encode categorical variables\n",
    "    label_encoders = {}\n",
    "    for col in categorical_cols:\n",
    "        le = LabelEncoder()\n",
    "        df_processed[col] = le.fit_transform(df_processed[col].astype(str))\n",
    "        label_encoders[col] = le\n",
    "    \n",
    "    print(\"Categorical variables encoded successfully!\")\n",
    "    print(\"\\nEncoding Details:\")\n",
    "    for col in categorical_cols:\n",
    "        le = label_encoders[col]\n",
    "        print(f\"{col}: {dict(zip(le.classes_, le.transform(le.classes_)))}\")\n",
    "    \n",
    "    print(\"\\nData after encoding:\")\n",
    "    print(df_processed.head())\n",
    "    print(\"\\nData types:\")\n",
    "    print(df_processed.dtypes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b90260c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    df_processed = df.copy()\n",
    "    \n",
    "    # Identify categorical and numerical columns\n",
    "    categorical_cols = df_processed.select_dtypes(include=['object']).columns.tolist()\n",
    "    numerical_cols = df_processed.select_dtypes(include=['int64', 'float64']).columns.tolist()\n",
    "    \n",
    "    # Remove target variable from numerical columns for processing\n",
    "    if 'charges' in numerical_cols:\n",
    "        numerical_cols.remove('charges')\n",
    "    \n",
    "    print(\"Categorical Columns:\", categorical_cols)\n",
    "    print(\"Numerical Columns:\", numerical_cols)\n",
    "    print(\"Target Variable: charges\")\n",
    "    print(f\"\\nTotal Features: {len(categorical_cols) + len(numerical_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1a50989",
   "metadata": {},
   "source": [
    "## 6. Data Preprocessing\n",
    "\n",
    "### 6.1 Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae5bd238",
   "metadata": {},
   "source": [
    "## 5. Methodology / Workflow\n",
    "\n",
    "### Experiment Workflow\n",
    "\n",
    "```\n",
    "┌─────────────────────────────┐\n",
    "│   1. Load Dataset           │\n",
    "│   (Insurance Data)          │\n",
    "└──────────────┬──────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────┐\n",
    "│ 2. Exploratory Data         │\n",
    "│    Analysis (EDA)           │\n",
    "│  - Data profiling           │\n",
    "│  - Correlation analysis     │\n",
    "│  - Distribution analysis    │\n",
    "└──────────────┬──────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────┐\n",
    "│ 3. Data Preprocessing       │\n",
    "│  - Handle missing values    │\n",
    "│  - Encode categorical vars  │\n",
    "│  - Feature scaling          │\n",
    "│  - Check for outliers       │\n",
    "└──────────────┬──────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────┐\n",
    "│ 4. Train-Test Split        │\n",
    "│  - 70% training            │\n",
    "│  - 30% testing             │\n",
    "└──────────────┬──────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────┐\n",
    "│ 5. Model Training           │\n",
    "│  - Multiple Regression      │\n",
    "│  - Lasso Regression         │\n",
    "│  - Ridge Regression         │\n",
    "└──────────────┬──────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────┐\n",
    "│ 6. Model Evaluation         │\n",
    "│  - Performance metrics      │\n",
    "│  - Visualizations           │\n",
    "│  - Residual analysis        │\n",
    "└──────────────┬──────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────┐\n",
    "│ 7. Hyperparameter Tuning    │\n",
    "│  - Alpha parameter tuning   │\n",
    "│  - GridSearchCV             │\n",
    "│  - Cross-validation         │\n",
    "└──────────────┬──────────────┘\n",
    "               │\n",
    "               ▼\n",
    "┌─────────────────────────────┐\n",
    "│ 8. Model Comparison &       │\n",
    "│    Final Analysis           │\n",
    "└─────────────────────────────┘\n",
    "```\n",
    "\n",
    "### Detailed Process:\n",
    "\n",
    "1. **Data Loading:** Import insurance dataset\n",
    "2. **EDA:** Analyze distributions, correlations, and relationships\n",
    "3. **Preprocessing:** Encode categoricals, scale features, split data\n",
    "4. **Model Training:** Train three regression models\n",
    "5. **Evaluation:** Calculate R², MSE, RMSE, MAE metrics\n",
    "6. **Tuning:** Optimize alpha parameters for Lasso and Ridge\n",
    "7. **Comparison:** Compare model performance and feature importance\n",
    "8. **Conclusions:** Identify best model and provide insights"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f22aad62",
   "metadata": {},
   "source": [
    "## 4. Algorithm Limitations\n",
    "\n",
    "### 4.1 Multiple Linear Regression Limitations\n",
    "\n",
    "1. **Assumes Linear Relationships:** Cannot capture non-linear patterns in data.\n",
    "\n",
    "2. **Sensitive to Multicollinearity:** Highly correlated features lead to unstable and unreliable coefficient estimates. The matrix $(\\mathbf{X}^T\\mathbf{X})$ becomes ill-conditioned.\n",
    "\n",
    "3. **Sensitive to Outliers:** Extreme values disproportionately affect coefficient estimates and predictions.\n",
    "\n",
    "4. **Assumes Homoscedasticity:** Assumes constant variance of residuals across all feature values. Violated when variance changes with features.\n",
    "\n",
    "5. **Feature Scaling Dependent:** Coefficients are scaled with feature magnitudes, making interpretation difficult and comparison across features problematic.\n",
    "\n",
    "6. **No Feature Selection:** Includes all features, even irrelevant ones, potentially reducing interpretability and generalization.\n",
    "\n",
    "7. **Overfitting Risk:** On high-dimensional data with many features, the model can overfit to training data.\n",
    "\n",
    "### 4.2 Lasso Regression Limitations\n",
    "\n",
    "1. **Arbitrary Feature Selection:** When features are highly correlated, Lasso arbitrarily selects one and sets others to zero, reducing interpretability.\n",
    "\n",
    "2. **Non-differentiable at Zero:** The L1 norm creates a non-smooth optimization problem, making gradient-based optimization challenging.\n",
    "\n",
    "3. **Computationally Expensive:** Requires specialized algorithms (coordinate descent) for efficient solving.\n",
    "\n",
    "4. **Single Alpha Dependency:** Performance highly sensitive to the regularization parameter $\\lambda$. Poor choice can lead to underfitting or overfitting.\n",
    "\n",
    "5. **Sample Size Requirement:** Requires sufficient samples relative to features. With $n < p$, performance may degrade.\n",
    "\n",
    "6. **Not Ideal for Group-Wise Correlated Features:** Unlike Group Lasso, cannot handle groups of correlated features well.\n",
    "\n",
    "### 4.3 Ridge Regression Limitations\n",
    "\n",
    "1. **No Feature Selection:** Ridge shrinks coefficients but rarely sets them to zero, keeping all features in the model.\n",
    "\n",
    "2. **Interpretation Challenge:** With many features, identifying truly important predictors is difficult due to distributed shrinkage.\n",
    "\n",
    "3. **Alpha Parameter Tuning:** Sensitive to $\\lambda$ selection; poor tuning leads to over/underfitting.\n",
    "\n",
    "4. **Computational Cost:** Computing $(\\mathbf{X}^T\\mathbf{X} + \\lambda \\mathbf{I})^{-1}$ can be expensive for large datasets.\n",
    "\n",
    "5. **Bias-Variance Trade-off:** Adds bias to reduce variance; incorrect $\\lambda$ can increase total error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64d77a85",
   "metadata": {},
   "source": [
    "## 3. Mathematical Formulation of Algorithms\n",
    "\n",
    "### 3.1 Multiple Linear Regression\n",
    "\n",
    "Multiple Linear Regression extends simple linear regression to multiple predictor variables:\n",
    "\n",
    "$$y = \\beta_0 + \\beta_1 x_1 + \\beta_2 x_2 + ... + \\beta_n x_n$$\n",
    "\n",
    "In matrix form:\n",
    "$$\\mathbf{y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}$$\n",
    "\n",
    "Where:\n",
    "- $\\mathbf{y}$ is the target vector (n × 1)\n",
    "- $\\mathbf{X}$ is the feature matrix (n × (p+1)) with intercept column\n",
    "- $\\boldsymbol{\\beta}$ is the coefficient vector (p+1 × 1)\n",
    "- $\\boldsymbol{\\epsilon}$ is the error vector (n × 1)\n",
    "\n",
    "**Cost Function (OLS):**\n",
    "$$J(\\boldsymbol{\\beta}) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\beta(\\mathbf{x}^{(i)}) - y^{(i)})^2 = \\frac{1}{2m} \\|\\mathbf{X}\\boldsymbol{\\beta} - \\mathbf{y}\\|_2^2$$\n",
    "\n",
    "**Closed-form Solution:**\n",
    "$$\\boldsymbol{\\beta} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{y}$$\n",
    "\n",
    "### 3.2 Lasso Regression (L1 Regularization)\n",
    "\n",
    "Lasso (Least Absolute Shrinkage and Selection Operator) adds L1 penalty to the cost function:\n",
    "\n",
    "$$J(\\boldsymbol{\\beta}) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\beta(\\mathbf{x}^{(i)}) - y^{(i)})^2 + \\lambda \\sum_{j=1}^{p} |\\beta_j|$$\n",
    "\n",
    "Or in compact form:\n",
    "$$J(\\boldsymbol{\\beta}) = \\frac{1}{2m} \\|\\mathbf{X}\\boldsymbol{\\beta} - \\mathbf{y}\\|_2^2 + \\lambda \\|\\boldsymbol{\\beta}\\|_1$$\n",
    "\n",
    "Where:\n",
    "- $\\lambda$ is the regularization parameter (controls strength of penalty)\n",
    "- $\\|\\boldsymbol{\\beta}\\|_1 = \\sum_{j=1}^{p} |\\beta_j|$ is the L1 norm\n",
    "\n",
    "**Key Property:** Lasso performs feature selection by driving coefficients to exactly zero, useful for identifying important features.\n",
    "\n",
    "### 3.3 Ridge Regression (L2 Regularization)\n",
    "\n",
    "Ridge Regression adds L2 penalty to the cost function:\n",
    "\n",
    "$$J(\\boldsymbol{\\beta}) = \\frac{1}{2m} \\sum_{i=1}^{m} (h_\\beta(\\mathbf{x}^{(i)}) - y^{(i)})^2 + \\lambda \\sum_{j=1}^{p} \\beta_j^2$$\n",
    "\n",
    "Or in compact form:\n",
    "$$J(\\boldsymbol{\\beta}) = \\frac{1}{2m} \\|\\mathbf{X}\\boldsymbol{\\beta} - \\mathbf{y}\\|_2^2 + \\lambda \\|\\boldsymbol{\\beta}\\|_2^2$$\n",
    "\n",
    "Where:\n",
    "- $\\lambda$ is the regularization parameter\n",
    "- $\\|\\boldsymbol{\\beta}\\|_2^2 = \\sum_{j=1}^{p} \\beta_j^2$ is the squared L2 norm\n",
    "\n",
    "**Closed-form Solution:**\n",
    "$$\\boldsymbol{\\beta} = (\\mathbf{X}^T\\mathbf{X} + \\lambda \\mathbf{I})^{-1}\\mathbf{X}^T\\mathbf{y}$$\n",
    "\n",
    "**Key Property:** Ridge shrinks coefficients proportionally but rarely sets them to exactly zero."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc43f193",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    # Target variable analysis\n",
    "    print(\"Target Variable Analysis:\")\n",
    "    print(f\"Target Variable: charges\")\n",
    "    print(f\"Mean: ${df['charges'].mean():.2f}\")\n",
    "    print(f\"Median: ${df['charges'].median():.2f}\")\n",
    "    print(f\"Std Dev: ${df['charges'].std():.2f}\")\n",
    "    print(f\"Min: ${df['charges'].min():.2f}\")\n",
    "    print(f\"Max: ${df['charges'].max():.2f}\")\n",
    "    \n",
    "    # Visualize target distribution and correlations\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 10))\n",
    "    \n",
    "    # Histogram\n",
    "    axes[0, 0].hist(df['charges'], bins=30, edgecolor='black', alpha=0.7, color='skyblue')\n",
    "    axes[0, 0].set_title('Distribution of Medical Charges', fontweight='bold', fontsize=12)\n",
    "    axes[0, 0].set_xlabel('Charges ($)')\n",
    "    axes[0, 0].set_ylabel('Frequency')\n",
    "    axes[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # Box plot\n",
    "    axes[0, 1].boxplot(df['charges'], vert=True)\n",
    "    axes[0, 1].set_title('Box Plot of Medical Charges', fontweight='bold', fontsize=12)\n",
    "    axes[0, 1].set_ylabel('Charges ($)')\n",
    "    axes[0, 1].grid(True, alpha=0.3, axis='y')\n",
    "    \n",
    "    # Correlation heatmap\n",
    "    correlation_data = df[['age', 'bmi', 'children', 'charges']].corr()\n",
    "    sns.heatmap(correlation_data, annot=True, fmt='.3f', cmap='coolwarm', ax=axes[1, 0], cbar_kws={'label': 'Correlation'})\n",
    "    axes[1, 0].set_title('Correlation Matrix (Numerical Features)', fontweight='bold', fontsize=12)\n",
    "    \n",
    "    # Categorical features distribution\n",
    "    categorical_features = df[['sex', 'smoker', 'region']].apply(pd.Series.value_counts)\n",
    "    axes[1, 1].axis('off')\n",
    "    axes[1, 1].text(0.1, 0.9, 'Categorical Features Summary:', fontsize=12, fontweight='bold', transform=axes[1, 1].transAxes)\n",
    "    summary_text = f\"Sex - Male: {df['sex'].value_counts().get('male', 0)}, Female: {df['sex'].value_counts().get('female', 0)}\\n\"\n",
    "    summary_text += f\"Smoker - Yes: {df['smoker'].value_counts().get('yes', 0)}, No: {df['smoker'].value_counts().get('no', 0)}\\n\"\n",
    "    summary_text += f\"Region - NE: {(df['region']=='northeast').sum()}, NW: {(df['region']=='northwest').sum()}\\n\"\n",
    "    summary_text += f\"           SE: {(df['region']=='southeast').sum()}, SW: {(df['region']=='southwest').sum()}\"\n",
    "    axes[1, 1].text(0.1, 0.5, summary_text, fontsize=10, transform=axes[1, 1].transAxes, verticalalignment='top', family='monospace')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0186ce04",
   "metadata": {},
   "outputs": [],
   "source": [
    "if df is not None:\n",
    "    print(\"Dataset Shape:\", df.shape)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"First Few Rows:\")\n",
    "    print(df.head())\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Data Types:\")\n",
    "    print(df.dtypes)\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Missing Values:\")\n",
    "    print(df.isnull().sum())\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Statistical Summary:\")\n",
    "    print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccd1d7de",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the insurance premium dataset\n",
    "# Note: Download from Kaggle and place in the same directory as this notebook\n",
    "try:\n",
    "    df = pd.read_csv('insurance.csv')\n",
    "    print(\"Dataset loaded successfully!\")\n",
    "except FileNotFoundError:\n",
    "    print(\"Dataset file 'insurance.csv' not found.\")\n",
    "    print(\"Please download from: https://www.kaggle.com/datasets/noordeen/insurance-premium-prediction/data\")\n",
    "    print(\"and place it in the same directory as this notebook.\")\n",
    "    df = None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f9beb63",
   "metadata": {},
   "source": [
    "## 2. Dataset Description\n",
    "\n",
    "The Insurance Premium Prediction dataset is designed to predict medical insurance costs based on individual characteristics. This is a classic dataset used for regression analysis and predicting continuous target variables.\n",
    "\n",
    "### Dataset Overview:\n",
    "- **Number of Records:** 1,338 observations (individuals)\n",
    "- **Number of Features:** 6 input features + 1 target variable\n",
    "- **Target Variable:** `charges` - individual medical costs billed by health insurance\n",
    "- **Data Types:** Mix of numerical and categorical features\n",
    "\n",
    "### Features Description:\n",
    "1. **age** (numerical): Age of the individual in years\n",
    "   - Range: 18-64 years\n",
    "   - Type: Continuous\n",
    "\n",
    "2. **sex** (categorical): Biological sex (male, female)\n",
    "   - Binary categorical variable\n",
    "   - Impact on insurance costs\n",
    "\n",
    "3. **bmi** (numerical): Body Mass Index\n",
    "   - Range: 15.96-53.13 kg/m²\n",
    "   - Numerical measure of body fat\n",
    "\n",
    "4. **children** (numerical): Number of children/dependents covered by insurance\n",
    "   - Range: 0-5 children\n",
    "   - Discrete numerical variable\n",
    "\n",
    "5. **smoker** (categorical): Smoking status (yes, no)\n",
    "   - Binary categorical variable\n",
    "   - Major factor in insurance costs\n",
    "\n",
    "6. **region** (categorical): US geographic region (northeast, northwest, southeast, southwest)\n",
    "   - Four-level categorical variable\n",
    "   - Geographic location\n",
    "\n",
    "### Target Variable:\n",
    "- **charges** (numerical): Individual medical costs charged by health insurance\n",
    "   - Continuous numerical variable\n",
    "   - Range varies based on individual characteristics\n",
    "   - Typically positively skewed due to high-cost cases\n",
    "\n",
    "### Data Characteristics:\n",
    "- **No Missing Values:** The dataset is clean with no missing entries\n",
    "- **Class Balance:** Not applicable (regression problem)\n",
    "- **Imbalance:** The target variable may have outliers (very high medical costs)\n",
    "- **Multicollinearity:** Potential correlation between age, BMI, and charges"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44889c34",
   "metadata": {},
   "source": [
    "## 1. Dataset Source\n",
    "\n",
    "**Dataset Name:** Insurance Premium Prediction Dataset  \n",
    "**Source:** https://www.kaggle.com/datasets/noordeen/insurance-premium-prediction/data  \n",
    "**Original Source:** Professor Eric Suess, California State University, East Bay (Spring 2017)  \n",
    "**File Size:** 50.26 kB  \n",
    "**License:** Unknown"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6806c7f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV, cross_val_score\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.linear_model import LinearRegression, Lasso, Ridge\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "%matplotlib inline\n",
    "sns.set_style('whitegrid')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "872bfaaa",
   "metadata": {},
   "source": [
    "# Machine Learning Experiment 2: Multiple, Lasso, and Ridge Regression on Insurance Premium Prediction\n",
    "\n",
    "**Experiment Title:** Predicting Medical Insurance Premiums Using Regularized Regression Models  \n",
    "**Date:** February 2026  \n",
    "**Objective:** To implement and compare Multiple Linear Regression, Lasso Regression, and Ridge Regression models on the Insurance Premium dataset for predicting medical expenses."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
